# Perplexity API Configuration (Recommended)
PERPLEXITY_API_KEY=your-key-here
# Default model selection for Perplexity API
# Options:
# - llama-3.1-sonar-small-128k-online (Fast, good for simple queries)
# - llama-3.1-sonar-large-128k-online (Default, balanced performance)
# - llama-3.1-sonar-huge-128k-online (Most capable, best for complex queries)
MODEL=llama-3.1-sonar-large-128k-online

# OpenRouter API Configuration (Alternative)
OPENROUTER_API_KEY=your-key-here
# OpenRouter model prefix: perplexity/
# Example: perplexity/llama-3.1-sonar-huge-128k-online

# Ollama Configuration
# No API key needed - uses local installation
# Prefix models with 'ollama:'
# Examples:
# MODEL=ollama:codellama
# MODEL=ollama:mistral

# Search Preferences
RESULT_TYPE=mixed  # Options: code, docs, mixed
STREAM_OUTPUT=true  # Enable/disable streaming responses
MAX_TOKENS=2048    # Maximum response length